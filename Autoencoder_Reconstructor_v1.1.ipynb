{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjoz_3nZZrJO"
      },
      "source": [
        "# **Autoencoder presentacion intermedia**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMBp0NWvafmk"
      },
      "source": [
        "# Librerias necesarias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ipuu4Xhud_db"
      },
      "outputs": [],
      "source": [
        "#Librerias visualizacion de datos\n",
        "from os import path\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pickle\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import random as rand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH3oefcdakPJ"
      },
      "source": [
        "# Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E_EQAat9eEvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce287799-88f9-4817-b236-18b18961037b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Están los datos en local o drive?\n",
        "path_stamp_dataset_21_new = None\n",
        "# path_stamp_dataset_21_new = 'E:Datos ZTF\\stamp_dataset_21_new.pkl'\n",
        "\n",
        "if path_stamp_dataset_21_new == None: # Sólo aplica si el path de drive coincide\n",
        "\n",
        "    drive.mount('/content/drive') #Montaje de Google Drive\n",
        "    path_stamp_dataset_21_new = '/content/drive/MyDrive/Proyecto Inteligencia/Datos ZTF/stamp_dataset_21_new.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TcqyjNeMJxM8"
      },
      "outputs": [],
      "source": [
        "# Función para cargar archivos .pkl\n",
        "def cargar_datos(ruta_archivo):\n",
        "    with open(ruta_archivo, 'rb') as archivo:\n",
        "        datos = pickle.load(archivo)\n",
        "    return datos\n",
        "\n",
        "#Cargar datasets\n",
        "datos_stamp_dataset_21_new = cargar_datos(path_stamp_dataset_21_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w58QbgynbLOb"
      },
      "source": [
        "# Mostrar datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIzlNph4baXs"
      },
      "source": [
        "# Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mijFwTATf713",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a6fa53-73e2-44cb-d743-eebf7a13d77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "  images\n",
            "    Shape: (72710, 21, 21, 3)\n",
            "  features\n",
            "    Shape: (72710, 26)\n",
            "  oid\n",
            "    Shape: (50594,)\n",
            "  class\n",
            "    Shape: (72710,)\n",
            "Test\n",
            "  images\n",
            "    Shape: (500, 21, 21, 3)\n",
            "  features\n",
            "    Shape: (500, 26)\n",
            "  oid\n",
            "    Shape: (500,)\n",
            "  class\n",
            "    Shape: (500,)\n",
            "Validation\n",
            "  images\n",
            "    Shape: (500, 21, 21, 3)\n",
            "  features\n",
            "    Shape: (500, 26)\n",
            "  oid\n",
            "    Shape: (500,)\n",
            "  class\n",
            "    Shape: (500,)\n"
          ]
        }
      ],
      "source": [
        "def print_keys(data, indent=0):\n",
        "    for key, value in data.items():\n",
        "        print(' ' * indent + str(key))\n",
        "        if isinstance(value, dict):\n",
        "            print_keys(value, indent + 2)\n",
        "        elif isinstance(value, (list, tuple)):\n",
        "            print(' ' * (indent + 2) + f'List/Tuple of length {len(value)}')\n",
        "        elif hasattr(value, 'shape'):\n",
        "            print(' ' * (indent + 2) + f'Shape: {value.shape}')\n",
        "        else:\n",
        "            print(' ' * (indent + 2) + str(type(value)))\n",
        "\n",
        "print_keys(datos_stamp_dataset_21_new)\n",
        "\n",
        "class StampDataset(Dataset):\n",
        "    def __init__(self, data, split):\n",
        "        self.images = data[split]['images']\n",
        "        self.features = data[split]['features']\n",
        "        self.label = data[split]['class']\n",
        "        self.split = split\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.features[idx], self.label[idx]\n",
        "\n",
        "train_dataset = StampDataset(datos_stamp_dataset_21_new, 'Train')\n",
        "val_dataset = StampDataset(datos_stamp_dataset_21_new, 'Validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdx1Hla0blvL"
      },
      "source": [
        "# Autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qc8IsVUBKp8W"
      },
      "outputs": [],
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__()\n",
        "        self.shape = args\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(self.shape)\n",
        "\n",
        "\n",
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvAutoencoder, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=4, stride=1),  # 21x21 -> 18x18\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),  # 18x18 -> 18x18\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 18x18 -> 9x9\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # 9x9 -> 9x9\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  # 9x9 -> 9x9\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 9x9 -> 4x4\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  # 4x4 -> 4x4\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),  # 4x4x64 -> 1024\n",
        "            nn.Linear(1024, 64),  # 1024 -> 64\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(64, 1024),  # 64 -> 1024\n",
        "            Reshape(-1, 64, 4, 4),  # Reshape to 64 channels, 4x4\n",
        "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # 4x4 -> 9x9\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # 9x9 -> 18x18\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=1, padding=1),  # 18x18 -> 18x18\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(size=(21, 21), mode='bilinear', align_corners=True),  # Upsample from 18x18 -> 21x21\n",
        "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=1, padding=1),  # 21x21x16 -> 21x21x3\n",
        "            nn.Sigmoid()  # Final output between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFjpC-AsbxHU"
      },
      "source": [
        "# Visualizacion y confirmacion de inputs y outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hYXzgmCtbtXS"
      },
      "outputs": [],
      "source": [
        "dummy_input= torch.randn(1, 3, 21, 21)\n",
        "model = ConvAutoencoder()\n",
        "output = model(dummy_input)\n",
        "#ocupar imagenes de 28x28 y cortar 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QQvCteKHl8wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d0bb1d2-659a-4cf0-eff1-68bab92f21b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([1, 3, 21, 21])\n",
            "After Conv2d, shape: torch.Size([1, 32, 18, 18])\n",
            "After ReLU, shape: torch.Size([1, 32, 18, 18])\n",
            "After Conv2d, shape: torch.Size([1, 32, 18, 18])\n",
            "After ReLU, shape: torch.Size([1, 32, 18, 18])\n",
            "After MaxPool2d, shape: torch.Size([1, 32, 9, 9])\n",
            "After Conv2d, shape: torch.Size([1, 64, 9, 9])\n",
            "After ReLU, shape: torch.Size([1, 64, 9, 9])\n",
            "After Conv2d, shape: torch.Size([1, 64, 9, 9])\n",
            "After ReLU, shape: torch.Size([1, 64, 9, 9])\n",
            "After MaxPool2d, shape: torch.Size([1, 64, 4, 4])\n",
            "After Conv2d, shape: torch.Size([1, 64, 4, 4])\n",
            "After ReLU, shape: torch.Size([1, 64, 4, 4])\n",
            "After Flatten, shape: torch.Size([1, 1024])\n",
            "After Linear, shape: torch.Size([1, 64])\n",
            "After ReLU, shape: torch.Size([1, 64])\n",
            "Encoder output shape: torch.Size([1, 64])\n",
            "After Linear, shape: torch.Size([1, 1024])\n",
            "After Reshape, shape: torch.Size([1, 64, 4, 4])\n",
            "After ConvTranspose2d, shape: torch.Size([1, 64, 8, 8])\n",
            "After ReLU, shape: torch.Size([1, 64, 8, 8])\n",
            "After ConvTranspose2d, shape: torch.Size([1, 32, 16, 16])\n",
            "After ReLU, shape: torch.Size([1, 32, 16, 16])\n",
            "After ConvTranspose2d, shape: torch.Size([1, 16, 16, 16])\n",
            "After ReLU, shape: torch.Size([1, 16, 16, 16])\n",
            "After Upsample, shape: torch.Size([1, 16, 21, 21])\n",
            "After ConvTranspose2d, shape: torch.Size([1, 3, 21, 21])\n",
            "After Sigmoid, shape: torch.Size([1, 3, 21, 21])\n",
            "Final output shape: torch.Size([1, 3, 21, 21])\n"
          ]
        }
      ],
      "source": [
        "def show_shapes(model, input_tensor):\n",
        "    x = input_tensor\n",
        "    print(f\"Input shape: {x.shape}\")\n",
        "\n",
        "    # Show shapes in the encoder\n",
        "    for layer in model.encoder:\n",
        "        x = layer(x)\n",
        "        print(f\"After {layer.__class__.__name__}, shape: {x.shape}\")\n",
        "\n",
        "    # Show the encoder output shape\n",
        "    print(f\"Encoder output shape: {x.shape}\")\n",
        "\n",
        "    # Show shapes in the decoder\n",
        "    for layer in model.decoder:\n",
        "        x = layer(x)\n",
        "        print(f\"After {layer.__class__.__name__}, shape: {x.shape}\")\n",
        "\n",
        "    # Final output shape\n",
        "    print(f\"Final output shape: {x.shape}\")\n",
        "\n",
        "# Create the dummy input\n",
        "dummy_input = torch.randn(1, 3, 21, 21)  # 21x21 input with 3 channels\n",
        "\n",
        "# Instantiate the model\n",
        "model = ConvAutoencoder()\n",
        "\n",
        "# Show shapes for each layer\n",
        "show_shapes(model, dummy_input)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo7gbo4CERa3"
      },
      "source": [
        "# Entrenamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "l09WC5H0JxM-"
      },
      "outputs": [],
      "source": [
        "def show_curves(curves):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(13, 5))\n",
        "    fig.set_facecolor('white')\n",
        "\n",
        "    epochs = np.arange(len(curves[\"val_loss\"])) + 1\n",
        "\n",
        "    ax[0].plot(epochs, curves['val_loss'], label='validation')\n",
        "    ax[0].plot(epochs, curves['train_loss'], label='training')\n",
        "    ax[0].set_xlabel('Epoch')\n",
        "    ax[0].set_ylabel('Loss')\n",
        "    ax[0].set_title('Loss evolution during training')\n",
        "    ax[0].legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5Mf055EVJxM_"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, n_epochs_tolerance):\n",
        "        self.n_epochs_tolerance = n_epochs_tolerance\n",
        "        self.epochs_with_no_improvement = 0\n",
        "        self.best_loss = np.inf\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        # En cada llamada aumentamos el número de épocas en que no hemos mejorado\n",
        "        self.epochs_with_no_improvement += 1\n",
        "\n",
        "        if val_loss <= self.best_loss:\n",
        "            # Si efectivamente mejoramos (menor loss de validación) reiniciamos el número de épocas sin mejora\n",
        "            self.best_loss = val_loss\n",
        "            self.epochs_with_no_improvement = 0\n",
        "\n",
        "        # Retornamos True si debemos detenernos y False si aún no\n",
        "        # Nos detenemos cuando el número de épocas sin mejora es mayor o igual que el número de épocas de tolerancia\n",
        "        return self.epochs_with_no_improvement >= self.n_epochs_tolerance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mZwBolQGMpfi"
      },
      "outputs": [],
      "source": [
        "def train_step(x_batch, model, optimizer, criterion, use_gpu):\n",
        "    # Predicción\n",
        "    x_batch = x_batch\n",
        "    if use_gpu:\n",
        "        x_batch = x_batch.cuda()\n",
        "\n",
        "    # Paso hacia adelante en el autoencoder para obtener la reconstrucción\n",
        "    x_reconstructed= model(x_batch)\n",
        "\n",
        "    # Cálculo de la pérdida entre la imagen original y la reconstruida\n",
        "    loss = criterion(x_reconstructed, x_batch)\n",
        "\n",
        "    # Actualización de parámetros\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return x_reconstructed, loss\n",
        "\n",
        "\n",
        "def evaluate(val_loader, model, criterion, use_gpu):\n",
        "    cumulative_loss = 0\n",
        "    cumulative_predictions = 0\n",
        "    data_count = 0\n",
        "\n",
        "    for x_val, _, _ in val_loader:\n",
        "        if use_gpu:\n",
        "            x_val = x_val.cuda()\n",
        "\n",
        "        x_val = x_val.float().permute(0, 3, 1, 2)\n",
        "\n",
        "        # Predicción de la reconstrucción\n",
        "        x_reconstructed= model(x_val)\n",
        "\n",
        "        # Cálculo de la pérdida\n",
        "        loss = criterion(x_reconstructed, x_val)\n",
        "\n",
        "        x_prediction = torch.argmax(x_reconstructed, axis=1).long()\n",
        "\n",
        "\n",
        "        cumulative_loss += loss.item()\n",
        "        data_count += x_val.shape[0]\n",
        "\n",
        "\n",
        "    val_loss = cumulative_loss / len(val_loader)\n",
        "\n",
        "    return val_loss\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_dataset,\n",
        "    val_dataset,\n",
        "    epochs,\n",
        "    criterion,\n",
        "    batch_size,\n",
        "    lr,\n",
        "    n_evaluations_per_epoch=6,\n",
        "    use_gpu=False,\n",
        "    early_stopping_tolerance=5,\n",
        "):\n",
        "    if use_gpu:\n",
        "        model.cuda()\n",
        "\n",
        "    early_stopping = EarlyStopping(n_epochs_tolerance=early_stopping_tolerance)\n",
        "\n",
        "    # Definición de dataloader\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=use_gpu)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False, pin_memory=use_gpu)\n",
        "\n",
        "    # Optimizador\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Listas para guardar curvas de entrenamiento\n",
        "    curves = {\n",
        "        \"train_loss\": [],\n",
        "        \"val_loss\": [],\n",
        "    }\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    iteration = 0\n",
        "\n",
        "    n_batches = len(train_loader)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\rEpoch {epoch + 1}/{epochs}\")\n",
        "        cumulative_train_loss = 0\n",
        "        train_loss_count = 0\n",
        "\n",
        "        # Entrenamiento del modelo\n",
        "        model.train()\n",
        "        for i, (img, _, _) in enumerate(train_loader):\n",
        "            if use_gpu:\n",
        "                img = img.cuda()\n",
        "            img = img.float().permute(0, 3, 1, 2)\n",
        "\n",
        "            # Paso de entrenamiento\n",
        "            x_reconstructed, loss = train_step(img, model, optimizer, criterion, use_gpu)\n",
        "\n",
        "            cumulative_train_loss += loss.item()\n",
        "            train_loss_count += 1\n",
        "\n",
        "            # Evaluaciones periódicas\n",
        "            if (i % (n_batches // n_evaluations_per_epoch) == 0) and (i > 0):\n",
        "                train_loss = cumulative_train_loss / train_loss_count\n",
        "                print(f\"Iteration {iteration} - Batch {i}/{len(train_loader)} - Train loss: {train_loss}\")\n",
        "\n",
        "            iteration += 1\n",
        "\n",
        "        # Evaluación del modelo en el conjunto de validación\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss = evaluate(val_loader, model, criterion, use_gpu)\n",
        "\n",
        "        print(f\"Val loss: {val_loss}\")\n",
        "\n",
        "        # Guardar pérdidas para la curva de aprendizaje\n",
        "        train_loss = cumulative_train_loss / train_loss_count\n",
        "        curves[\"train_loss\"].append(train_loss)\n",
        "        curves[\"val_loss\"].append(val_loss)\n",
        "\n",
        "        if early_stopping(val_loss):\n",
        "            print(\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "    print()\n",
        "    print(f\"Tiempo total de entrenamiento: {time.perf_counter() - t0:.4f} [s]\")\n",
        "\n",
        "    model.cpu()\n",
        "\n",
        "    return curves\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU2VcRP_JxM_"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "dropout_p = 0.5\n",
        "batch_size = 64\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "epochs = 30\n",
        "model = ConvAutoencoder()\n",
        "\n",
        "curves = train_model(\n",
        "    model,\n",
        "    train_dataset,\n",
        "    val_dataset,\n",
        "    epochs,\n",
        "    criterion,\n",
        "    batch_size,\n",
        "    lr,\n",
        "    use_gpu=True,\n",
        ")\n",
        "\n",
        "show_curves(curves)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "intelli",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}